package throughput

import (
	"fmt"
	"sort"
	"sync"
	"time"

	"github.com/nullxjx/LLM-Profiler/common"
	"github.com/nullxjx/LLM-Profiler/config"
	"github.com/nullxjx/LLM-Profiler/infer"
	"github.com/nullxjx/LLM-Profiler/infer/param"

	log "github.com/sirupsen/logrus"
)

// ThroughputTest ååé‡æµ‹è¯•
func ThroughputTest(cfg *config.Config) (string, string) {
	clearCache()

	prompts, err := common.ReadPrompts(cfg.InputTokens)
	if err != nil {
		log.Errorf("read inputs error: %v", err)
		return "", ""
	}
	if cfg.StartConcurrency > cfg.EndConcurrency {
		log.Errorf("StartConcurrency > EndConcurrency")
		return "", ""
	}

	// é€æ­¥å¢åŠ å¹¶å‘åº¦ï¼Œæµ‹è¯•ååé‡
	for concurrency := cfg.StartConcurrency; concurrency <= cfg.EndConcurrency; concurrency += cfg.Increment {
		log.Infof("ğŸ™ğŸ™ğŸ™ start testing at concurrency %v", concurrency)
		if step(cfg, prompts, concurrency) {
			break
		}

		// ç­‰å¾…ä¸Šä¸€è½®å®Œå…¨ç»“æŸï¼Œä¸ºäº†é¿å…è¿™è½®è¯·æ±‚å¯¹ä¸‹ä¸€è½®é€ æˆå½±å“ todo @nullxjx éœ€è¦æ”¹è¿›ï¼Œå¦‚ä½•æ›´ç²¾å‡†åˆ¤æ–­ä¸Šä¸€è½®å·²ç»ç»“æŸ
		time.Sleep(30 * time.Second)
	}

	return finish(cfg)
}

// step è¿›è¡Œä¸€è½®æµ‹è¯•ï¼Œè¿”å›trueï¼Œåˆ™åœæ­¢ä¸‹ä¸€è½®æµ‹è¯•ï¼Œè¿”å›falseï¼Œåˆ™ç»§ç»­ä¸‹ä¸€è½®æµ‹è¯•
func step(cfg *config.Config, prompts []string, concurrency int) bool {
	// è®¾ç½®æµ‹è¯•æŒç»­æ—¶é—´
	duration := time.Duration(cfg.Duration) * time.Minute

	wg := &sync.WaitGroup{}
	var mu sync.Mutex
	ticker := time.NewTicker(duration / time.Duration(concurrency))
	results := make(chan param.Result, concurrency)
	var totalCount int32 = 0
	var successCount int32 = 0
	var failedCount int32 = 0
	var inputIndex = 0

	startTime := time.Now()
	for start := time.Now(); time.Since(start) < duration; {
		select {
		case <-ticker.C:
			wg.Add(1)
			go sendRequest(&param.RequestParam{
				ServiceURL:   fmt.Sprintf("%s:%d", cfg.ServerIp, cfg.Port),
				ModelName:    cfg.Model.Name,
				ModelVersion: cfg.Model.Version,
				Wg:           wg,
				Prompts:      prompts,
				Result:       results,
				SuccessCount: &successCount,
				FailedCount:  &failedCount,
				TotalCount:   &totalCount,
				InputIndex:   inputIndex,
				Timeout:      cfg.RequestTimeout,
				StopWords:    cfg.StopWords,
				MaxTokens:    cfg.MaxTokens,
			}, cfg)
		default:
			time.Sleep(10 * time.Millisecond) // Avoid busy waiting
		}
		// ä½¿ç”¨äº’æ–¥é”ä¿æŠ¤å¯¹ inputIndex çš„è®¿é—®å’Œæ›´æ–°
		mu.Lock()
		inputIndex = (inputIndex + 1) % len(prompts)
		mu.Unlock()
	}
	log.Infof("waiting for all goroutines to finish...")
	wg.Wait() // é˜»å¡ï¼Œç›´åˆ° WaitGroup çš„è®¡æ•°å™¨å˜ä¸º 0
	close(results)
	//log.Infof("all goroutines have finished")

	endTime := time.Now()
	startTimeStr := startTime.Format("2006-01-02 15:04:05")
	endTimeStr := endTime.Format("2006-01-02 15:04:05")
	timeSpent := float64(endTime.Sub(startTime)) / float64(time.Second)
	countMetrics(&StatisticsParam{
		Concurrency:    concurrency,
		Duration:       timeSpent, // å•ä½æ˜¯ç§’
		Results:        results,
		TotalCount:     &totalCount,
		SuccessCount:   &successCount,
		FailedCount:    &failedCount,
		TimeThresholds: cfg.TimeThresholds,
		SaveDir:        cfg.SaveDir,
		StartTime:      startTimeStr,
		EndTime:        endTimeStr,
	})
	metric := statistics[concurrency]
	log.Debugf("[time: %.3fs, total: %v, success: %v, fail: %v] "+
		"| Server: [ %.3f tokens/s, %.3f req/s ] | Client: %.3f tokens/s "+
		"| Stream thresholds: %v%% | MaxStreamSpeed: %.1f tokens/s "+
		"| Prompt length: %v",
		timeSpent, metric.Total, metric.Success, metric.Fail,
		metric.OutputTokensPerSecond, metric.RequestPerSecond, metric.ClientOutputTokensPerSecond,
		cfg.StreamSpeedThresholds, cfg.MaxStreamSpeed, cfg.InputTokens)
	return stopCheck(cfg, concurrency)
}

func sendRequest(param *param.RequestParam, cfg *config.Config) {
	if cfg.Stream {
		go sendStreamRequest(param, cfg)
		return
	}

	if cfg.Backend == "vllm" {
		go infer.SendVllmRequest(param)
	} else if cfg.Backend == "tgi" {
		go infer.SendTgiRequest(param)
	} else if cfg.Backend == "triton-vllm" {
		go infer.SendTritonVllmRequest(param)
	} else if cfg.Backend == "trt" {
		go infer.SendTrtRequest(param)
	} else {
		panic(fmt.Sprintf("unsupported backend: %s", cfg.Backend))
	}
}

func sendStreamRequest(param *param.RequestParam, cfg *config.Config) {
	if cfg.Backend == "vllm" {
		go infer.SendVllmStreamRequest(param)
	} else if cfg.Backend == "trt" {
		go infer.SendTrtStreamRequest(param)
	} else {
		panic(fmt.Sprintf("unsupported stream on backend: %s", cfg.Backend))
	}
}

func saveResult(cfg *config.Config) {
	var valueList []*StatisticsSummary
	for _, value := range statistics {
		valueList = append(valueList, value)
	}
	// æŒ‰ç…§Concurrencyå¯¹ç»“æœæ’åº
	sort.Slice(valueList, func(i, j int) bool {
		return valueList[i].Concurrency < valueList[j].Concurrency
	})

	common.Save2Json(valueList, fmt.Sprintf("%s/statistics_%s.json", cfg.SaveDir, time.Now().Format("2006-01-02-15-04-05")))
}

func finish(cfg *config.Config) (string, string) {
	// æœ‰ä¸€äº›é…ç½®é¡¹æ¯”è¾ƒæ•æ„Ÿï¼Œä¸è¦å­˜åˆ°ç»“æœä¸­å»ï¼Œè¿™é‡Œæ‰‹åŠ¨è¿‡æ»¤æ‰è¿™äº›é…ç½®
	log.Infof("saving config file...")

	cfg_ := *cfg

	common.Save2Json(cfg_, fmt.Sprintf("%s/config_%s.json", cfg.SaveDir, time.Now().Format("2006-01-02-15-04-05")))

	// åªä¿ç•™æœ€æ–°ä¸€ä¸ªç»Ÿè®¡æ–‡ä»¶
	common.KeepFinalResult(cfg.SaveDir)

	if !cfg.Save2Cos {
		log.Debugf("See result in %v", cfg.SaveDir)
		return "", ""
	}

	log.Debugf("saving all files to cos...")
	downloadUrl, dstDir, err := common.SaveFilesToCos(cfg)
	if err != nil {
		log.Errorf("â—ï¸â—ï¸â— upload to cos failed")
		log.Debugf("ğŸ¥³ğŸ¤©ğŸ¥° Done!!!")
		return "", ""
	}

	if cfg.SendMsg {
		log.Debugf("download statistics result via ğŸ‘‰ %s ğŸ‘ˆ", downloadUrl)
		common.SendMsg(cfg, downloadUrl, dstDir)
	}
	log.Debugf("ğŸ¥³ğŸ¤©ğŸ¥° Done!!!")
	return downloadUrl, dstDir
}
